{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Займемся поиском start/end токенов ответа в вопросе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/work/tinkoff/.venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/user/work/tinkoff/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "# from transformers import AutoTokenizer, pipeline\n",
    "# from langchain import HuggingFacePipeline\n",
    "# from langchain.chains import RetrievalQA\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 62310, 'title': 'SberChallenge', 'question': 'чем представлены органические остатки?', 'answers': {'text': ['известковыми выделениями сине-зелёных водорослей'], 'answer_start': [109]}}, page_content='\"\\\\u0412 \\\\u043f\\\\u0440\\\\u043e\\\\u0442\\\\u0435\\\\u0440\\\\u043e\\\\u0437\\\\u043e\\\\u0439\\\\u0441\\\\u043a\\\\u0438\\\\u0445 \\\\u043e\\\\u0442\\\\u043b\\\\u043e\\\\u0436\\\\u0435\\\\u043d\\\\u0438\\\\u044f\\\\u0445 \\\\u043e\\\\u0440\\\\u0433\\\\u0430\\\\u043d\\\\u0438\\\\u0447\\\\u0435\\\\u0441\\\\u043a\\\\u0438\\\\u0435 \\\\u043e\\\\u0441\\\\u0442\\\\u0430\\\\u0442\\\\u043a\\\\u0438 \\\\u0432\\\\u0441\\\\u0442\\\\u0440\\\\u0435\\\\u0447\\\\u0430\\\\u044e\\\\u0442\\\\u0441\\\\u044f \\\\u043d\\\\u0430\\\\u043c\\\\u043d\\\\u043e\\\\u0433\\\\u043e \\\\u0447\\\\u0430\\\\u0449\\\\u0435, \\\\u0447\\\\u0435\\\\u043c \\\\u0432 \\\\u0430\\\\u0440\\\\u0445\\\\u0435\\\\u0439\\\\u0441\\\\u043a\\\\u0438\\\\u0445. \\\\u041e\\\\u043d\\\\u0438 \\\\u043f\\\\u0440\\\\u0435\\\\u0434\\\\u0441\\\\u0442\\\\u0430\\\\u0432\\\\u043b\\\\u0435\\\\u043d\\\\u044b \\\\u0438\\\\u0437\\\\u0432\\\\u0435\\\\u0441\\\\u0442\\\\u043a\\\\u043e\\\\u0432\\\\u044b\\\\u043c\\\\u0438 \\\\u0432\\\\u044b\\\\u0434\\\\u0435\\\\u043b\\\\u0435\\\\u043d\\\\u0438\\\\u044f\\\\u043c\\\\u0438 \\\\u0441\\\\u0438\\\\u043d\\\\u0435-\\\\u0437\\\\u0435\\\\u043b\\\\u0451\\\\u043d\\\\u044b\\\\u0445 \\\\u0432\\\\u043e\\\\u0434\\\\u043e\\\\u0440\\\\u043e\\\\u0441\\\\u043b\\\\u0435\\\\u0439, \\\\u0445\\\\u043e\\\\u0434\\\\u0430\\\\u043c\\\\u0438 \\\\u0447\\\\u0435\\\\u0440\\\\u0432\\\\u0435\\\\u0439, \\\\u043e\\\\u0441\\\\u0442\\\\u0430\\\\u0442\\\\u043a\\\\u0430\\\\u043c\\\\u0438 \\\\u043a\\\\u0438\\\\u0448\\\\u0435\\\\u0447\\\\u043d\\\\u043e\\\\u043f\\\\u043e\\\\u043b\\\\u043e\\\\u0441\\\\u0442\\\\u043d\\\\u044b\\\\u0445. \\\\u041a\\\\u0440\\\\u043e\\\\u043c\\\\u0435 \\\\u0438\\\\u0437\\\\u0432\\\\u0435\\\\u0441\\\\u0442\\\\u043a\\\\u043e\\\\u0432\\\\u044b\\\\u0445 \\\\u0432\\\\u043e\\\\u0434\\\\u043e\\\\u0440\\\\u043e\\\\u0441\\\\u043b\\\\u0435\\\\u0439, \\\\u043a \\\\u0447\\\\u0438\\\\u0441\\\\u043b\\\\u0443 \\\\u0434\\\\u0440\\\\u0435\\\\u0432\\\\u043d\\\\u0435\\\\u0439\\\\u0448\\\\u0438\\\\u0445 \\\\u0440\\\\u0430\\\\u0441\\\\u0442\\\\u0438\\\\u0442\\\\u0435\\\\u043b\\\\u044c\\\\u043d\\\\u044b\\\\u0445 \\\\u043e\\\\u0441\\\\u0442\\\\u0430\\\\u0442\\\\u043a\\\\u043e\\\\u0432 \\\\u043e\\\\u0442\\\\u043d\\\\u043e\\\\u0441\\\\u044f\\\\u0442\\\\u0441\\\\u044f \\\\u0441\\\\u043a\\\\u043e\\\\u043f\\\\u043b\\\\u0435\\\\u043d\\\\u0438\\\\u044f \\\\u0433\\\\u0440\\\\u0430\\\\u0444\\\\u0438\\\\u0442\\\\u043e-\\\\u0443\\\\u0433\\\\u043b\\\\u0438\\\\u0441\\\\u0442\\\\u043e\\\\u0433\\\\u043e \\\\u0432\\\\u0435\\\\u0449\\\\u0435\\\\u0441\\\\u0442\\\\u0432\\\\u0430, \\\\u043e\\\\u0431\\\\u0440\\\\u0430\\\\u0437\\\\u043e\\\\u0432\\\\u0430\\\\u0432\\\\u0448\\\\u0435\\\\u0433\\\\u043e\\\\u0441\\\\u044f \\\\u0432 \\\\u0440\\\\u0435\\\\u0437\\\\u0443\\\\u043b\\\\u044c\\\\u0442\\\\u0430\\\\u0442\\\\u0435 \\\\u0440\\\\u0430\\\\u0437\\\\u043b\\\\u043e\\\\u0436\\\\u0435\\\\u043d\\\\u0438\\\\u044f Corycium enigmaticum. \\\\u0412 \\\\u043a\\\\u0440\\\\u0435\\\\u043c\\\\u043d\\\\u0438\\\\u0441\\\\u0442\\\\u044b\\\\u0445 \\\\u0441\\\\u043b\\\\u0430\\\\u043d\\\\u0446\\\\u0430\\\\u0445 \\\\u0436\\\\u0435\\\\u043b\\\\u0435\\\\u0437\\\\u043e\\\\u0440\\\\u0443\\\\u0434\\\\u043d\\\\u043e\\\\u0439 \\\\u0444\\\\u043e\\\\u0440\\\\u043c\\\\u0430\\\\u0446\\\\u0438\\\\u0438 \\\\u041a\\\\u0430\\\\u043d\\\\u0430\\\\u0434\\\\u044b \\\\u043d\\\\u0430\\\\u0439\\\\u0434\\\\u0435\\\\u043d\\\\u044b \\\\u043d\\\\u0438\\\\u0442\\\\u0435\\\\u0432\\\\u0438\\\\u0434\\\\u043d\\\\u044b\\\\u0435 \\\\u0432\\\\u043e\\\\u0434\\\\u043e\\\\u0440\\\\u043e\\\\u0441\\\\u043b\\\\u0438, \\\\u0433\\\\u0440\\\\u0438\\\\u0431\\\\u043d\\\\u044b\\\\u0435 \\\\u043d\\\\u0438\\\\u0442\\\\u0438 \\\\u0438 \\\\u0444\\\\u043e\\\\u0440\\\\u043c\\\\u044b, \\\\u0431\\\\u043b\\\\u0438\\\\u0437\\\\u043a\\\\u0438\\\\u0435 \\\\u0441\\\\u043e\\\\u0432\\\\u0440\\\\u0435\\\\u043c\\\\u0435\\\\u043d\\\\u043d\\\\u044b\\\\u043c \\\\u043a\\\\u043e\\\\u043a\\\\u043a\\\\u043e\\\\u043b\\\\u0438\\\\u0442\\\\u043e\\\\u0444\\\\u043e\\\\u0440\\\\u0438\\\\u0434\\\\u0430\\\\u043c. \\\\u0412 \\\\u0436\\\\u0435\\\\u043b\\\\u0435\\\\u0437\\\\u0438\\\\u0441\\\\u0442\\\\u044b\\\\u0445 \\\\u043a\\\\u0432\\\\u0430\\\\u0440\\\\u0446\\\\u0438\\\\u0442\\\\u0430\\\\u0445 \\\\u0421\\\\u0435\\\\u0432\\\\u0435\\\\u0440\\\\u043d\\\\u043e\\\\u0439 \\\\u0410\\\\u043c\\\\u0435\\\\u0440\\\\u0438\\\\u043a\\\\u0438 \\\\u0438 \\\\u0421\\\\u0438\\\\u0431\\\\u0438\\\\u0440\\\\u0438 \\\\u043e\\\\u0431\\\\u043d\\\\u0430\\\\u0440\\\\u0443\\\\u0436\\\\u0435\\\\u043d\\\\u044b \\\\u0436\\\\u0435\\\\u043b\\\\u0435\\\\u0437\\\\u0438\\\\u0441\\\\u0442\\\\u044b\\\\u0435 \\\\u043f\\\\u0440\\\\u043e\\\\u0434\\\\u0443\\\\u043a\\\\u0442\\\\u044b \\\\u0436\\\\u0438\\\\u0437\\\\u043d\\\\u0435\\\\u0434\\\\u0435\\\\u044f\\\\u0442\\\\u0435\\\\u043b\\\\u044c\\\\u043d\\\\u043e\\\\u0441\\\\u0442\\\\u0438 \\\\u0431\\\\u0430\\\\u043a\\\\u0442\\\\u0435\\\\u0440\\\\u0438\\\\u0439.\"')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"kuznetsoffandrey/sberquad\"\n",
    "page_content_column = \"context\"\n",
    "\n",
    "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Что-то с кодировкой, поэтому исправляем\n",
    "for document in data:\n",
    "    document.page_content = document.page_content.encode().decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_885217/2651821630.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Берем какую-нибудь bert для расчёта эмбединга, этот справляется вроде бы нелпохо\n",
    "modelPath = \"sergeyzh/LaBSE-ru-turbo\"\n",
    "\n",
    "model_kwargs = {'device':'cpu'}\n",
    "\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0207399632781744, 0.019484564661979675, -0.06904035806655884]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Проверка\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(data, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"чем представлены органические остатки?\"\n",
    "searchDocs = db.similarity_search(question)\n",
    "print(searchDocs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.\"\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"чем представлены органические остатки?\")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "# https://www.kaggle.com/code/tttrrraaahhh/rubert-sberquad/notebook\n",
    "model_name = \"./ru-bert-finetuned-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Функция для QA\n",
    "def answer_question(question, context):\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    answer_start = outputs.start_logits.argmax()\n",
    "    answer_end = outputs.end_logits.argmax() + 1\n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "скопления графито - углистого вещества\n"
     ]
    }
   ],
   "source": [
    "question = \"что относится к числу древнейших растительных остатков?\"\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "print(answer_question(question, docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "# question = \"\"\n",
    "\n",
    "\n",
    "# docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "# retrived_text = '\\n\\n'.join([doc.page_content for doc in docs])\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": f'''Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "#         context: {retrived_text}'''\n",
    "#     },\n",
    "#     {\"role\": \"user\", \"content\": f'{question}'}\n",
    "# ]\n",
    "# prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "# outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "# question = input()\n",
    "# # <|system|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Who is Thomas Jefferson?\"\n",
    "# result = qa.invoke({\"query\": question})\n",
    "# print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
